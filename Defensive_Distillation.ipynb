{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Defensive_Distillation.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyNGA5eKg/7gFeOYwjQs7Eti"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"XOaMA-KEfFNI","colab_type":"text"},"source":["IMPORTS"]},{"cell_type":"code","metadata":{"id":"d8O41BfHjfKb","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1597043081385,"user_tz":-270,"elapsed":3071,"user":{"displayName":"Bardia Esmaeili","photoUrl":"","userId":"04990908225233460923"}}},"source":["from keras.models import Sequential\n","from keras.layers import Dense, Dropout, Activation, Flatten\n","from keras.layers import Conv2D, MaxPooling2D\n","from keras.optimizers import SGD\n","\n","import tensorflow as tf\n","import os\n","from tensorflow.keras.datasets import mnist\n","import numpy as np\n","from tensorflow.keras.utils import to_categorical"],"execution_count":1,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9DSP23ZdfK9i","colab_type":"text"},"source":["Prepare MNIST Dataset"]},{"cell_type":"code","metadata":{"id":"32q6rDuPo_2Q","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1597043081387,"user_tz":-270,"elapsed":3063,"user":{"displayName":"Bardia Esmaeili","photoUrl":"","userId":"04990908225233460923"}}},"source":["class MNIST:\n","  def __init__(self):\n","    (self.train_data, self.train_labels), (self.test_data, self.test_labels) = mnist.load_data()\n","    self.train_data, self.test_data = self.train_data[..., np.newaxis] / 255.0, self.test_data[..., np.newaxis] / 255.0\n","    self.train_labels, self.test_labels = to_categorical(self.train_labels, 10), to_categorical(self.test_labels, 10)\n","    # print(self.train_labels.shape, self.test_labels.shape)\n","    self.validation_data, self.validation_labels = self.train_data[:5000,...], self.train_labels[:5000,...]\n","    self.train_data, self.train_labels = self.train_data[5000:,...], self.train_labels[5000:,...]"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"XHV7JHrZn2eQ","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1597043081388,"user_tz":-270,"elapsed":3059,"user":{"displayName":"Bardia Esmaeili","photoUrl":"","userId":"04990908225233460923"}}},"source":["def train(data, file_name, params, num_epochs=50, batch_size=128, train_temp=1, init=None):\n","  \"\"\"\n","  Standard neural network training procedure.\n","  \"\"\"\n","  model = Sequential()\n","\n","  # print(data.train_data.shape)\n","  \n","  model.add(Conv2D(params[0], (3, 3),\n","                          input_shape=data.train_data.shape[1:]))\n","  model.add(Activation('relu'))\n","  model.add(Conv2D(params[1], (3, 3)))\n","  model.add(Activation('relu'))\n","  model.add(MaxPooling2D(pool_size=(2, 2)))\n","\n","  model.add(Conv2D(params[2], (3, 3)))\n","  model.add(Activation('relu'))\n","  model.add(Conv2D(params[3], (3, 3)))\n","  model.add(Activation('relu'))\n","  model.add(MaxPooling2D(pool_size=(2, 2)))\n","\n","  model.add(Flatten())\n","  model.add(Dense(params[4]))\n","  model.add(Activation('relu'))\n","  model.add(Dropout(0.5))\n","  model.add(Dense(params[5]))\n","  model.add(Activation('relu'))\n","  model.add(Dense(10))\n","  \n","  if init != None:\n","    model.load_weights(init + '/model_weights.h5')\n","    print(f'loaded from {init}')\n","\n","  def fn(correct, predicted):\n","    return tf.nn.softmax_cross_entropy_with_logits(labels=correct,\n","                                                      logits=predicted/train_temp)\n","\n","  sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n","  \n","  model.compile(loss=fn,\n","                optimizer=sgd,\n","                metrics=['accuracy'])\n","  \n","  model.fit(data.train_data, data.train_labels,\n","            batch_size=batch_size,\n","            validation_data=(data.validation_data, data.validation_labels),\n","            epochs=num_epochs,\n","            shuffle=True)\n","  \n","  # print(f'file name is: {file_name}')\n","  if file_name != None:\n","    if not os.path.isdir(file_name):\n","      os.makedirs(file_name)\n","      print(f\"save made dir {file_name}\")\n","    model.save(file_name + '/model_weights.h5')\n","\n","  return model"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"SDrKYqYCdnCH","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1597043148658,"user_tz":-270,"elapsed":1268,"user":{"displayName":"Bardia Esmaeili","photoUrl":"","userId":"04990908225233460923"}}},"source":["def train_distillation(data, file_name, params, num_epochs=50, batch_size=128, train_temp=1):\n","  \"\"\"\n","  Train a network using defensive distillation.\n","  Distillation as a Defense to Adversarial Perturbations against Deep Neural Networks\n","  Nicolas Papernot, Patrick McDaniel, Xi Wu, Somesh Jha, Ananthram Swami\n","  IEEE S&P, 2016.\n","  \"\"\"\n","  if not os.path.exists(file_name+\"_init\"):\n","    # Train for one epoch to get a good starting point.\n","    train(data, file_name+\"_init\", params, 1, batch_size)\n","  \n","\n","  # now train the teacher at the given temperature\n","  print(f'training teacher with tempurature {train_temp}')\n","  teacher = train(data, file_name+\"_teacher\", params, num_epochs, batch_size, train_temp,\n","                  init=file_name+\"_init\")\n","\n","  # evaluate the labels at temperature t\n","  predicted = teacher.predict(data.train_data)\n","  data.train_labels = tf.nn.softmax(predicted/train_temp)\n","\n","  # train the student model at temperature t\n","  print(f'trained student with tempurature {train_temp}')\n","  student = train(data, file_name+\"_student\", params, num_epochs, batch_size, train_temp, init=file_name+\"_init\")\n","\n","  # and finally we predict at temperature 1\n","  predicted = student.predict(data.train_data)\n","\n","  # print(predicted)\n","\n","  return teacher, student"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"8Qi5qqnRuP0K","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1597043181164,"user_tz":-270,"elapsed":4197,"user":{"displayName":"Bardia Esmaeili","photoUrl":"","userId":"04990908225233460923"}}},"source":["!rm -rf models"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"veKcjQq5ds2g","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1597043181167,"user_tz":-270,"elapsed":1896,"user":{"displayName":"Bardia Esmaeili","photoUrl":"","userId":"04990908225233460923"}}},"source":["if not os.path.isdir('models'):\n","  os.makedirs('models')"],"execution_count":8,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7oI9tTR3fbFR","colab_type":"text"},"source":["Train Teacher and Student Network with temprature 100"]},{"cell_type":"code","metadata":{"id":"Q1bKKgVSdurt","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1597043809325,"user_tz":-270,"elapsed":629641,"user":{"displayName":"Bardia Esmaeili","photoUrl":"","userId":"04990908225233460923"}},"outputId":"22ac6dfc-4217-4993-baa4-521ecb3b2d9a"},"source":["teacher, student = train_distillation(MNIST(), \"/content/models/mnist_distilled_100\", [32, 32, 64, 64, 200, 200], num_epochs=50, train_temp=100)\n"],"execution_count":9,"outputs":[{"output_type":"stream","text":["(60000, 10) (10000, 10)\n","430/430 [==============================] - 6s 15ms/step - loss: 0.5285 - accuracy: 0.8266 - val_loss: 0.0918 - val_accuracy: 0.9714\n","save made dir /content/models/mnist_distilled_100_init\n","training teacher with tempurature 100\n","loaded from /content/models/mnist_distilled_100_init\n","Epoch 1/50\n","430/430 [==============================] - 6s 14ms/step - loss: 0.3672 - accuracy: 0.9400 - val_loss: 0.0887 - val_accuracy: 0.9738\n","Epoch 2/50\n","430/430 [==============================] - 6s 14ms/step - loss: 0.1234 - accuracy: 0.9637 - val_loss: 0.0701 - val_accuracy: 0.9798\n","Epoch 3/50\n","430/430 [==============================] - 6s 15ms/step - loss: 0.1019 - accuracy: 0.9701 - val_loss: 0.0616 - val_accuracy: 0.9816\n","Epoch 4/50\n","430/430 [==============================] - 6s 14ms/step - loss: 0.0884 - accuracy: 0.9729 - val_loss: 0.0559 - val_accuracy: 0.9836\n","Epoch 5/50\n","430/430 [==============================] - 6s 14ms/step - loss: 0.0776 - accuracy: 0.9763 - val_loss: 0.0519 - val_accuracy: 0.9846\n","Epoch 6/50\n","430/430 [==============================] - 6s 14ms/step - loss: 0.0711 - accuracy: 0.9785 - val_loss: 0.0453 - val_accuracy: 0.9870\n","Epoch 7/50\n","430/430 [==============================] - 6s 14ms/step - loss: 0.0652 - accuracy: 0.9794 - val_loss: 0.0455 - val_accuracy: 0.9874\n","Epoch 8/50\n","430/430 [==============================] - 6s 14ms/step - loss: 0.0604 - accuracy: 0.9814 - val_loss: 0.0441 - val_accuracy: 0.9866\n","Epoch 9/50\n","430/430 [==============================] - 6s 14ms/step - loss: 0.0562 - accuracy: 0.9830 - val_loss: 0.0431 - val_accuracy: 0.9892\n","Epoch 10/50\n","430/430 [==============================] - 6s 14ms/step - loss: 0.0518 - accuracy: 0.9835 - val_loss: 0.0423 - val_accuracy: 0.9878\n","Epoch 11/50\n","430/430 [==============================] - 6s 14ms/step - loss: 0.0503 - accuracy: 0.9845 - val_loss: 0.0416 - val_accuracy: 0.9890\n","Epoch 12/50\n","430/430 [==============================] - 6s 14ms/step - loss: 0.0483 - accuracy: 0.9855 - val_loss: 0.0420 - val_accuracy: 0.9886\n","Epoch 13/50\n","430/430 [==============================] - 6s 14ms/step - loss: 0.0430 - accuracy: 0.9866 - val_loss: 0.0409 - val_accuracy: 0.9886\n","Epoch 14/50\n","430/430 [==============================] - 6s 14ms/step - loss: 0.0406 - accuracy: 0.9875 - val_loss: 0.0412 - val_accuracy: 0.9880\n","Epoch 15/50\n","430/430 [==============================] - 6s 14ms/step - loss: 0.0400 - accuracy: 0.9869 - val_loss: 0.0387 - val_accuracy: 0.9904\n","Epoch 16/50\n","430/430 [==============================] - 6s 14ms/step - loss: 0.0378 - accuracy: 0.9884 - val_loss: 0.0391 - val_accuracy: 0.9892\n","Epoch 17/50\n","430/430 [==============================] - 6s 14ms/step - loss: 0.0353 - accuracy: 0.9885 - val_loss: 0.0399 - val_accuracy: 0.9902\n","Epoch 18/50\n","430/430 [==============================] - 6s 14ms/step - loss: 0.0351 - accuracy: 0.9888 - val_loss: 0.0368 - val_accuracy: 0.9908\n","Epoch 19/50\n","430/430 [==============================] - 6s 14ms/step - loss: 0.0337 - accuracy: 0.9895 - val_loss: 0.0362 - val_accuracy: 0.9918\n","Epoch 20/50\n","430/430 [==============================] - 6s 14ms/step - loss: 0.0314 - accuracy: 0.9900 - val_loss: 0.0361 - val_accuracy: 0.9910\n","Epoch 21/50\n","430/430 [==============================] - 6s 14ms/step - loss: 0.0305 - accuracy: 0.9905 - val_loss: 0.0347 - val_accuracy: 0.9912\n","Epoch 22/50\n","430/430 [==============================] - 6s 14ms/step - loss: 0.0283 - accuracy: 0.9907 - val_loss: 0.0362 - val_accuracy: 0.9916\n","Epoch 23/50\n","430/430 [==============================] - 6s 14ms/step - loss: 0.0256 - accuracy: 0.9918 - val_loss: 0.0394 - val_accuracy: 0.9916\n","Epoch 24/50\n","430/430 [==============================] - 6s 14ms/step - loss: 0.0263 - accuracy: 0.9916 - val_loss: 0.0373 - val_accuracy: 0.9910\n","Epoch 25/50\n","430/430 [==============================] - 6s 14ms/step - loss: 0.0252 - accuracy: 0.9918 - val_loss: 0.0357 - val_accuracy: 0.9916\n","Epoch 26/50\n","430/430 [==============================] - 6s 14ms/step - loss: 0.0240 - accuracy: 0.9923 - val_loss: 0.0378 - val_accuracy: 0.9914\n","Epoch 27/50\n","430/430 [==============================] - 6s 14ms/step - loss: 0.0239 - accuracy: 0.9924 - val_loss: 0.0351 - val_accuracy: 0.9916\n","Epoch 28/50\n","430/430 [==============================] - 6s 14ms/step - loss: 0.0237 - accuracy: 0.9920 - val_loss: 0.0329 - val_accuracy: 0.9926\n","Epoch 29/50\n","430/430 [==============================] - 6s 14ms/step - loss: 0.0217 - accuracy: 0.9930 - val_loss: 0.0367 - val_accuracy: 0.9914\n","Epoch 30/50\n","430/430 [==============================] - 6s 14ms/step - loss: 0.0210 - accuracy: 0.9930 - val_loss: 0.0361 - val_accuracy: 0.9918\n","Epoch 31/50\n","430/430 [==============================] - 6s 14ms/step - loss: 0.0217 - accuracy: 0.9925 - val_loss: 0.0367 - val_accuracy: 0.9916\n","Epoch 32/50\n","430/430 [==============================] - 6s 14ms/step - loss: 0.0206 - accuracy: 0.9933 - val_loss: 0.0375 - val_accuracy: 0.9918\n","Epoch 33/50\n","430/430 [==============================] - 6s 14ms/step - loss: 0.0184 - accuracy: 0.9941 - val_loss: 0.0379 - val_accuracy: 0.9918\n","Epoch 34/50\n","430/430 [==============================] - 6s 14ms/step - loss: 0.0179 - accuracy: 0.9943 - val_loss: 0.0411 - val_accuracy: 0.9914\n","Epoch 35/50\n","430/430 [==============================] - 6s 14ms/step - loss: 0.0185 - accuracy: 0.9939 - val_loss: 0.0380 - val_accuracy: 0.9918\n","Epoch 36/50\n","430/430 [==============================] - 6s 14ms/step - loss: 0.0156 - accuracy: 0.9949 - val_loss: 0.0404 - val_accuracy: 0.9916\n","Epoch 37/50\n","430/430 [==============================] - 6s 14ms/step - loss: 0.0178 - accuracy: 0.9942 - val_loss: 0.0372 - val_accuracy: 0.9912\n","Epoch 38/50\n","430/430 [==============================] - 6s 14ms/step - loss: 0.0159 - accuracy: 0.9950 - val_loss: 0.0391 - val_accuracy: 0.9918\n","Epoch 39/50\n","430/430 [==============================] - 6s 14ms/step - loss: 0.0164 - accuracy: 0.9943 - val_loss: 0.0395 - val_accuracy: 0.9908\n","Epoch 40/50\n","430/430 [==============================] - 6s 14ms/step - loss: 0.0170 - accuracy: 0.9942 - val_loss: 0.0388 - val_accuracy: 0.9916\n","Epoch 41/50\n","430/430 [==============================] - 6s 14ms/step - loss: 0.0156 - accuracy: 0.9946 - val_loss: 0.0408 - val_accuracy: 0.9912\n","Epoch 42/50\n","430/430 [==============================] - 6s 14ms/step - loss: 0.0143 - accuracy: 0.9951 - val_loss: 0.0388 - val_accuracy: 0.9926\n","Epoch 43/50\n","430/430 [==============================] - 6s 14ms/step - loss: 0.0146 - accuracy: 0.9951 - val_loss: 0.0408 - val_accuracy: 0.9922\n","Epoch 44/50\n","430/430 [==============================] - 6s 14ms/step - loss: 0.0144 - accuracy: 0.9952 - val_loss: 0.0397 - val_accuracy: 0.9912\n","Epoch 45/50\n","430/430 [==============================] - 6s 14ms/step - loss: 0.0141 - accuracy: 0.9952 - val_loss: 0.0411 - val_accuracy: 0.9916\n","Epoch 46/50\n","430/430 [==============================] - 6s 14ms/step - loss: 0.0129 - accuracy: 0.9956 - val_loss: 0.0401 - val_accuracy: 0.9920\n","Epoch 47/50\n","430/430 [==============================] - 6s 14ms/step - loss: 0.0133 - accuracy: 0.9955 - val_loss: 0.0361 - val_accuracy: 0.9924\n","Epoch 48/50\n","430/430 [==============================] - 6s 14ms/step - loss: 0.0118 - accuracy: 0.9961 - val_loss: 0.0427 - val_accuracy: 0.9916\n","Epoch 49/50\n","430/430 [==============================] - 6s 14ms/step - loss: 0.0128 - accuracy: 0.9959 - val_loss: 0.0372 - val_accuracy: 0.9922\n","Epoch 50/50\n","430/430 [==============================] - 6s 14ms/step - loss: 0.0113 - accuracy: 0.9961 - val_loss: 0.0390 - val_accuracy: 0.9924\n","save made dir /content/models/mnist_distilled_100_teacher\n","trained student with tempurature 100\n","loaded from /content/models/mnist_distilled_100_init\n","Epoch 1/50\n","430/430 [==============================] - 6s 14ms/step - loss: 0.3673 - accuracy: 0.9400 - val_loss: 0.0872 - val_accuracy: 0.9744\n","Epoch 2/50\n","430/430 [==============================] - 6s 14ms/step - loss: 0.1213 - accuracy: 0.9635 - val_loss: 0.0671 - val_accuracy: 0.9792\n","Epoch 3/50\n","430/430 [==============================] - 6s 14ms/step - loss: 0.0974 - accuracy: 0.9704 - val_loss: 0.0588 - val_accuracy: 0.9830\n","Epoch 4/50\n","430/430 [==============================] - 6s 14ms/step - loss: 0.0852 - accuracy: 0.9737 - val_loss: 0.0525 - val_accuracy: 0.9852\n","Epoch 5/50\n","430/430 [==============================] - 6s 14ms/step - loss: 0.0746 - accuracy: 0.9765 - val_loss: 0.0538 - val_accuracy: 0.9844\n","Epoch 6/50\n","430/430 [==============================] - 6s 14ms/step - loss: 0.0672 - accuracy: 0.9790 - val_loss: 0.0484 - val_accuracy: 0.9868\n","Epoch 7/50\n","430/430 [==============================] - 6s 14ms/step - loss: 0.0618 - accuracy: 0.9812 - val_loss: 0.0486 - val_accuracy: 0.9856\n","Epoch 8/50\n","430/430 [==============================] - 6s 14ms/step - loss: 0.0570 - accuracy: 0.9824 - val_loss: 0.0440 - val_accuracy: 0.9880\n","Epoch 9/50\n","430/430 [==============================] - 6s 14ms/step - loss: 0.0529 - accuracy: 0.9833 - val_loss: 0.0462 - val_accuracy: 0.9872\n","Epoch 10/50\n","430/430 [==============================] - 6s 14ms/step - loss: 0.0516 - accuracy: 0.9842 - val_loss: 0.0419 - val_accuracy: 0.9896\n","Epoch 11/50\n","430/430 [==============================] - 6s 14ms/step - loss: 0.0465 - accuracy: 0.9853 - val_loss: 0.0404 - val_accuracy: 0.9894\n","Epoch 12/50\n","430/430 [==============================] - 6s 14ms/step - loss: 0.0444 - accuracy: 0.9859 - val_loss: 0.0429 - val_accuracy: 0.9888\n","Epoch 13/50\n","430/430 [==============================] - 6s 14ms/step - loss: 0.0406 - accuracy: 0.9871 - val_loss: 0.0390 - val_accuracy: 0.9898\n","Epoch 14/50\n","430/430 [==============================] - 6s 14ms/step - loss: 0.0383 - accuracy: 0.9881 - val_loss: 0.0415 - val_accuracy: 0.9886\n","Epoch 15/50\n","430/430 [==============================] - 6s 14ms/step - loss: 0.0378 - accuracy: 0.9880 - val_loss: 0.0393 - val_accuracy: 0.9898\n","Epoch 16/50\n","430/430 [==============================] - 6s 14ms/step - loss: 0.0357 - accuracy: 0.9890 - val_loss: 0.0396 - val_accuracy: 0.9910\n","Epoch 17/50\n","430/430 [==============================] - 6s 14ms/step - loss: 0.0333 - accuracy: 0.9891 - val_loss: 0.0409 - val_accuracy: 0.9900\n","Epoch 18/50\n","430/430 [==============================] - 6s 14ms/step - loss: 0.0318 - accuracy: 0.9901 - val_loss: 0.0389 - val_accuracy: 0.9906\n","Epoch 19/50\n","430/430 [==============================] - 6s 14ms/step - loss: 0.0301 - accuracy: 0.9906 - val_loss: 0.0397 - val_accuracy: 0.9898\n","Epoch 20/50\n","430/430 [==============================] - 6s 14ms/step - loss: 0.0307 - accuracy: 0.9900 - val_loss: 0.0393 - val_accuracy: 0.9904\n","Epoch 21/50\n","430/430 [==============================] - 6s 14ms/step - loss: 0.0283 - accuracy: 0.9907 - val_loss: 0.0374 - val_accuracy: 0.9896\n","Epoch 22/50\n","430/430 [==============================] - 6s 14ms/step - loss: 0.0288 - accuracy: 0.9907 - val_loss: 0.0373 - val_accuracy: 0.9908\n","Epoch 23/50\n","430/430 [==============================] - 6s 14ms/step - loss: 0.0263 - accuracy: 0.9921 - val_loss: 0.0387 - val_accuracy: 0.9906\n","Epoch 24/50\n","430/430 [==============================] - 6s 14ms/step - loss: 0.0260 - accuracy: 0.9915 - val_loss: 0.0400 - val_accuracy: 0.9908\n","Epoch 25/50\n","430/430 [==============================] - 6s 14ms/step - loss: 0.0258 - accuracy: 0.9919 - val_loss: 0.0431 - val_accuracy: 0.9902\n","Epoch 26/50\n","430/430 [==============================] - 6s 14ms/step - loss: 0.0236 - accuracy: 0.9930 - val_loss: 0.0399 - val_accuracy: 0.9906\n","Epoch 27/50\n","430/430 [==============================] - 6s 14ms/step - loss: 0.0225 - accuracy: 0.9930 - val_loss: 0.0372 - val_accuracy: 0.9924\n","Epoch 28/50\n","430/430 [==============================] - 6s 14ms/step - loss: 0.0230 - accuracy: 0.9928 - val_loss: 0.0377 - val_accuracy: 0.9918\n","Epoch 29/50\n","430/430 [==============================] - 6s 14ms/step - loss: 0.0216 - accuracy: 0.9935 - val_loss: 0.0379 - val_accuracy: 0.9910\n","Epoch 30/50\n","430/430 [==============================] - 6s 14ms/step - loss: 0.0213 - accuracy: 0.9930 - val_loss: 0.0394 - val_accuracy: 0.9926\n","Epoch 31/50\n","430/430 [==============================] - 6s 14ms/step - loss: 0.0199 - accuracy: 0.9942 - val_loss: 0.0376 - val_accuracy: 0.9920\n","Epoch 32/50\n","430/430 [==============================] - 6s 14ms/step - loss: 0.0203 - accuracy: 0.9939 - val_loss: 0.0394 - val_accuracy: 0.9914\n","Epoch 33/50\n","430/430 [==============================] - 6s 14ms/step - loss: 0.0191 - accuracy: 0.9944 - val_loss: 0.0393 - val_accuracy: 0.9910\n","Epoch 34/50\n","430/430 [==============================] - 6s 14ms/step - loss: 0.0174 - accuracy: 0.9948 - val_loss: 0.0384 - val_accuracy: 0.9916\n","Epoch 35/50\n","430/430 [==============================] - 6s 14ms/step - loss: 0.0183 - accuracy: 0.9947 - val_loss: 0.0397 - val_accuracy: 0.9906\n","Epoch 36/50\n","430/430 [==============================] - 6s 14ms/step - loss: 0.0180 - accuracy: 0.9947 - val_loss: 0.0372 - val_accuracy: 0.9924\n","Epoch 37/50\n","430/430 [==============================] - 6s 14ms/step - loss: 0.0167 - accuracy: 0.9952 - val_loss: 0.0406 - val_accuracy: 0.9914\n","Epoch 38/50\n","430/430 [==============================] - 6s 14ms/step - loss: 0.0162 - accuracy: 0.9955 - val_loss: 0.0412 - val_accuracy: 0.9916\n","Epoch 39/50\n","430/430 [==============================] - 6s 14ms/step - loss: 0.0167 - accuracy: 0.9947 - val_loss: 0.0405 - val_accuracy: 0.9914\n","Epoch 40/50\n","430/430 [==============================] - 6s 14ms/step - loss: 0.0157 - accuracy: 0.9952 - val_loss: 0.0409 - val_accuracy: 0.9914\n","Epoch 41/50\n","430/430 [==============================] - 6s 14ms/step - loss: 0.0156 - accuracy: 0.9954 - val_loss: 0.0392 - val_accuracy: 0.9924\n","Epoch 42/50\n","430/430 [==============================] - 6s 14ms/step - loss: 0.0157 - accuracy: 0.9956 - val_loss: 0.0422 - val_accuracy: 0.9918\n","Epoch 43/50\n","430/430 [==============================] - 6s 14ms/step - loss: 0.0159 - accuracy: 0.9952 - val_loss: 0.0396 - val_accuracy: 0.9920\n","Epoch 44/50\n","430/430 [==============================] - 6s 14ms/step - loss: 0.0152 - accuracy: 0.9955 - val_loss: 0.0402 - val_accuracy: 0.9920\n","Epoch 45/50\n","430/430 [==============================] - 6s 14ms/step - loss: 0.0145 - accuracy: 0.9959 - val_loss: 0.0389 - val_accuracy: 0.9920\n","Epoch 46/50\n","430/430 [==============================] - 6s 14ms/step - loss: 0.0137 - accuracy: 0.9962 - val_loss: 0.0385 - val_accuracy: 0.9920\n","Epoch 47/50\n","430/430 [==============================] - 6s 14ms/step - loss: 0.0146 - accuracy: 0.9957 - val_loss: 0.0407 - val_accuracy: 0.9912\n","Epoch 48/50\n","430/430 [==============================] - 6s 14ms/step - loss: 0.0133 - accuracy: 0.9962 - val_loss: 0.0413 - val_accuracy: 0.9918\n","Epoch 49/50\n","430/430 [==============================] - 6s 14ms/step - loss: 0.0138 - accuracy: 0.9964 - val_loss: 0.0387 - val_accuracy: 0.9922\n","Epoch 50/50\n","430/430 [==============================] - 6s 14ms/step - loss: 0.0132 - accuracy: 0.9965 - val_loss: 0.0403 - val_accuracy: 0.9914\n","save made dir /content/models/mnist_distilled_100_student\n","[[ -919.1505    236.64026  1078.2926  ...  1900.2402   -336.48563\n","    238.92288]\n"," [-1343.4554   -631.223     480.8172  ...   113.5021   1768.5437\n","   1132.3427 ]\n"," [-1097.633     449.92764  -671.7691  ...   295.83066   655.80115\n","   1931.5377 ]\n"," ...\n"," [  -90.13795  -968.7739  -1477.122   ...  -958.814     570.8288\n","   1306.1686 ]\n"," [  854.54333  -638.4662    355.38898 ... -1433.265     311.46\n","   -456.13263]\n"," [   86.73879  -792.40857   438.14337 ...  -772.1453   2618.0784\n","    582.6502 ]]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"VyUgV3Kvfgsu","colab_type":"text"},"source":["Train a Base Model for comparision with Student"]},{"cell_type":"code","metadata":{"id":"IM9bgVTxiqQ4","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1597044248287,"user_tz":-270,"elapsed":305470,"user":{"displayName":"Bardia Esmaeili","photoUrl":"","userId":"04990908225233460923"}},"outputId":"2dd228ee-85a3-4215-e2bf-de0ae0ae9d41"},"source":["base_model = train(data=MNIST(), file_name='/content/models/mnist_base', params=[32, 32, 64, 64, 200, 200])"],"execution_count":12,"outputs":[{"output_type":"stream","text":["(60000, 10) (10000, 10)\n","Epoch 1/50\n","430/430 [==============================] - 6s 15ms/step - loss: 0.5286 - accuracy: 0.8222 - val_loss: 0.0876 - val_accuracy: 0.9742\n","Epoch 2/50\n","430/430 [==============================] - 6s 14ms/step - loss: 0.1263 - accuracy: 0.9619 - val_loss: 0.0601 - val_accuracy: 0.9830\n","Epoch 3/50\n","430/430 [==============================] - 6s 14ms/step - loss: 0.0904 - accuracy: 0.9721 - val_loss: 0.0554 - val_accuracy: 0.9846\n","Epoch 4/50\n","430/430 [==============================] - 6s 14ms/step - loss: 0.0717 - accuracy: 0.9783 - val_loss: 0.0462 - val_accuracy: 0.9870\n","Epoch 5/50\n","430/430 [==============================] - 6s 14ms/step - loss: 0.0631 - accuracy: 0.9816 - val_loss: 0.0378 - val_accuracy: 0.9900\n","Epoch 6/50\n","430/430 [==============================] - 6s 14ms/step - loss: 0.0547 - accuracy: 0.9831 - val_loss: 0.0359 - val_accuracy: 0.9902\n","Epoch 7/50\n","430/430 [==============================] - 6s 14ms/step - loss: 0.0471 - accuracy: 0.9858 - val_loss: 0.0381 - val_accuracy: 0.9892\n","Epoch 8/50\n","430/430 [==============================] - 6s 14ms/step - loss: 0.0424 - accuracy: 0.9869 - val_loss: 0.0369 - val_accuracy: 0.9902\n","Epoch 9/50\n","430/430 [==============================] - 6s 14ms/step - loss: 0.0381 - accuracy: 0.9879 - val_loss: 0.0356 - val_accuracy: 0.9908\n","Epoch 10/50\n","430/430 [==============================] - 6s 14ms/step - loss: 0.0369 - accuracy: 0.9886 - val_loss: 0.0315 - val_accuracy: 0.9924\n","Epoch 11/50\n","430/430 [==============================] - 6s 14ms/step - loss: 0.0329 - accuracy: 0.9897 - val_loss: 0.0320 - val_accuracy: 0.9924\n","Epoch 12/50\n","430/430 [==============================] - 6s 14ms/step - loss: 0.0289 - accuracy: 0.9910 - val_loss: 0.0359 - val_accuracy: 0.9920\n","Epoch 13/50\n","430/430 [==============================] - 6s 14ms/step - loss: 0.0284 - accuracy: 0.9911 - val_loss: 0.0328 - val_accuracy: 0.9920\n","Epoch 14/50\n","430/430 [==============================] - 6s 14ms/step - loss: 0.0270 - accuracy: 0.9915 - val_loss: 0.0324 - val_accuracy: 0.9922\n","Epoch 15/50\n","430/430 [==============================] - 6s 14ms/step - loss: 0.0242 - accuracy: 0.9921 - val_loss: 0.0292 - val_accuracy: 0.9932\n","Epoch 16/50\n","430/430 [==============================] - 6s 14ms/step - loss: 0.0233 - accuracy: 0.9920 - val_loss: 0.0302 - val_accuracy: 0.9928\n","Epoch 17/50\n","430/430 [==============================] - 6s 14ms/step - loss: 0.0212 - accuracy: 0.9933 - val_loss: 0.0333 - val_accuracy: 0.9926\n","Epoch 18/50\n","430/430 [==============================] - 6s 14ms/step - loss: 0.0182 - accuracy: 0.9940 - val_loss: 0.0304 - val_accuracy: 0.9932\n","Epoch 19/50\n","430/430 [==============================] - 6s 14ms/step - loss: 0.0177 - accuracy: 0.9945 - val_loss: 0.0337 - val_accuracy: 0.9920\n","Epoch 20/50\n","430/430 [==============================] - 6s 14ms/step - loss: 0.0179 - accuracy: 0.9942 - val_loss: 0.0296 - val_accuracy: 0.9934\n","Epoch 21/50\n","430/430 [==============================] - 6s 14ms/step - loss: 0.0161 - accuracy: 0.9947 - val_loss: 0.0315 - val_accuracy: 0.9936\n","Epoch 22/50\n","430/430 [==============================] - 6s 14ms/step - loss: 0.0157 - accuracy: 0.9947 - val_loss: 0.0320 - val_accuracy: 0.9932\n","Epoch 23/50\n","430/430 [==============================] - 6s 14ms/step - loss: 0.0147 - accuracy: 0.9951 - val_loss: 0.0349 - val_accuracy: 0.9930\n","Epoch 24/50\n","430/430 [==============================] - 6s 14ms/step - loss: 0.0145 - accuracy: 0.9948 - val_loss: 0.0320 - val_accuracy: 0.9932\n","Epoch 25/50\n","430/430 [==============================] - 6s 14ms/step - loss: 0.0153 - accuracy: 0.9948 - val_loss: 0.0328 - val_accuracy: 0.9934\n","Epoch 26/50\n","430/430 [==============================] - 6s 14ms/step - loss: 0.0136 - accuracy: 0.9954 - val_loss: 0.0337 - val_accuracy: 0.9932\n","Epoch 27/50\n","430/430 [==============================] - 6s 14ms/step - loss: 0.0121 - accuracy: 0.9961 - val_loss: 0.0349 - val_accuracy: 0.9932\n","Epoch 28/50\n","430/430 [==============================] - 6s 14ms/step - loss: 0.0122 - accuracy: 0.9959 - val_loss: 0.0315 - val_accuracy: 0.9934\n","Epoch 29/50\n","430/430 [==============================] - 6s 14ms/step - loss: 0.0116 - accuracy: 0.9961 - val_loss: 0.0354 - val_accuracy: 0.9926\n","Epoch 30/50\n","430/430 [==============================] - 6s 14ms/step - loss: 0.0114 - accuracy: 0.9959 - val_loss: 0.0286 - val_accuracy: 0.9942\n","Epoch 31/50\n","430/430 [==============================] - 6s 14ms/step - loss: 0.0100 - accuracy: 0.9965 - val_loss: 0.0352 - val_accuracy: 0.9920\n","Epoch 32/50\n","430/430 [==============================] - 6s 14ms/step - loss: 0.0094 - accuracy: 0.9968 - val_loss: 0.0343 - val_accuracy: 0.9932\n","Epoch 33/50\n","430/430 [==============================] - 6s 14ms/step - loss: 0.0091 - accuracy: 0.9970 - val_loss: 0.0333 - val_accuracy: 0.9942\n","Epoch 34/50\n","430/430 [==============================] - 6s 15ms/step - loss: 0.0082 - accuracy: 0.9973 - val_loss: 0.0326 - val_accuracy: 0.9932\n","Epoch 35/50\n","430/430 [==============================] - 6s 14ms/step - loss: 0.0081 - accuracy: 0.9972 - val_loss: 0.0355 - val_accuracy: 0.9930\n","Epoch 36/50\n","430/430 [==============================] - 6s 14ms/step - loss: 0.0088 - accuracy: 0.9971 - val_loss: 0.0355 - val_accuracy: 0.9928\n","Epoch 37/50\n","430/430 [==============================] - 6s 14ms/step - loss: 0.0076 - accuracy: 0.9973 - val_loss: 0.0337 - val_accuracy: 0.9936\n","Epoch 38/50\n","430/430 [==============================] - 6s 14ms/step - loss: 0.0088 - accuracy: 0.9971 - val_loss: 0.0286 - val_accuracy: 0.9942\n","Epoch 39/50\n","430/430 [==============================] - 6s 14ms/step - loss: 0.0070 - accuracy: 0.9977 - val_loss: 0.0330 - val_accuracy: 0.9938\n","Epoch 40/50\n","430/430 [==============================] - 6s 14ms/step - loss: 0.0080 - accuracy: 0.9972 - val_loss: 0.0402 - val_accuracy: 0.9930\n","Epoch 41/50\n","430/430 [==============================] - 6s 14ms/step - loss: 0.0080 - accuracy: 0.9974 - val_loss: 0.0294 - val_accuracy: 0.9940\n","Epoch 42/50\n","430/430 [==============================] - 6s 14ms/step - loss: 0.0069 - accuracy: 0.9976 - val_loss: 0.0327 - val_accuracy: 0.9944\n","Epoch 43/50\n","430/430 [==============================] - 6s 14ms/step - loss: 0.0062 - accuracy: 0.9979 - val_loss: 0.0372 - val_accuracy: 0.9936\n","Epoch 44/50\n","430/430 [==============================] - 6s 14ms/step - loss: 0.0082 - accuracy: 0.9974 - val_loss: 0.0339 - val_accuracy: 0.9946\n","Epoch 45/50\n","430/430 [==============================] - 6s 14ms/step - loss: 0.0061 - accuracy: 0.9979 - val_loss: 0.0334 - val_accuracy: 0.9934\n","Epoch 46/50\n","430/430 [==============================] - 6s 14ms/step - loss: 0.0056 - accuracy: 0.9979 - val_loss: 0.0413 - val_accuracy: 0.9934\n","Epoch 47/50\n","430/430 [==============================] - 6s 14ms/step - loss: 0.0067 - accuracy: 0.9977 - val_loss: 0.0375 - val_accuracy: 0.9940\n","Epoch 48/50\n","430/430 [==============================] - 6s 14ms/step - loss: 0.0060 - accuracy: 0.9980 - val_loss: 0.0319 - val_accuracy: 0.9938\n","Epoch 49/50\n","430/430 [==============================] - 6s 14ms/step - loss: 0.0055 - accuracy: 0.9983 - val_loss: 0.0380 - val_accuracy: 0.9928\n","Epoch 50/50\n","430/430 [==============================] - 6s 14ms/step - loss: 0.0061 - accuracy: 0.9981 - val_loss: 0.0322 - val_accuracy: 0.9942\n","save made dir /content/models/mnist_base\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"hrmXDVbAfrxe","colab_type":"text"},"source":["Install and import Foolbox"]},{"cell_type":"code","metadata":{"id":"CmFJo1qUPRph","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":383},"executionInfo":{"status":"ok","timestamp":1597044704748,"user_tz":-270,"elapsed":9482,"user":{"displayName":"Bardia Esmaeili","photoUrl":"","userId":"04990908225233460923"}},"outputId":"1ed5aac4-11ad-4380-e2ae-8c70f7fd3ab0"},"source":["!pip3 install foolbox==3.0.0b1"],"execution_count":23,"outputs":[{"output_type":"stream","text":["Collecting foolbox==3.0.0b1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/48/33/221fb1e1a9b9646a2ab3ebda421e3ca00943da531a6227c37cf5ace37a5e/foolbox-3.0.0b1-py3-none-any.whl (1.6MB)\n","\r\u001b[K     |▏                               | 10kB 16.8MB/s eta 0:00:01\r\u001b[K     |▍                               | 20kB 1.7MB/s eta 0:00:01\r\u001b[K     |▋                               | 30kB 2.2MB/s eta 0:00:01\r\u001b[K     |▉                               | 40kB 2.5MB/s eta 0:00:01\r\u001b[K     |█                               | 51kB 2.0MB/s eta 0:00:01\r\u001b[K     |█▏                              | 61kB 2.2MB/s eta 0:00:01\r\u001b[K     |█▍                              | 71kB 2.4MB/s eta 0:00:01\r\u001b[K     |█▋                              | 81kB 2.7MB/s eta 0:00:01\r\u001b[K     |█▉                              | 92kB 2.8MB/s eta 0:00:01\r\u001b[K     |██                              | 102kB 2.7MB/s eta 0:00:01\r\u001b[K     |██▏                             | 112kB 2.7MB/s eta 0:00:01\r\u001b[K     |██▍                             | 122kB 2.7MB/s eta 0:00:01\r\u001b[K     |██▋                             | 133kB 2.7MB/s eta 0:00:01\r\u001b[K     |██▉                             | 143kB 2.7MB/s eta 0:00:01\r\u001b[K     |███                             | 153kB 2.7MB/s eta 0:00:01\r\u001b[K     |███▏                            | 163kB 2.7MB/s eta 0:00:01\r\u001b[K     |███▍                            | 174kB 2.7MB/s eta 0:00:01\r\u001b[K     |███▋                            | 184kB 2.7MB/s eta 0:00:01\r\u001b[K     |███▉                            | 194kB 2.7MB/s eta 0:00:01\r\u001b[K     |████                            | 204kB 2.7MB/s eta 0:00:01\r\u001b[K     |████▏                           | 215kB 2.7MB/s eta 0:00:01\r\u001b[K     |████▍                           | 225kB 2.7MB/s eta 0:00:01\r\u001b[K     |████▋                           | 235kB 2.7MB/s eta 0:00:01\r\u001b[K     |████▊                           | 245kB 2.7MB/s eta 0:00:01\r\u001b[K     |█████                           | 256kB 2.7MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 266kB 2.7MB/s eta 0:00:01\r\u001b[K     |█████▍                          | 276kB 2.7MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 286kB 2.7MB/s eta 0:00:01\r\u001b[K     |█████▊                          | 296kB 2.7MB/s eta 0:00:01\r\u001b[K     |██████                          | 307kB 2.7MB/s eta 0:00:01\r\u001b[K     |██████▏                         | 317kB 2.7MB/s eta 0:00:01\r\u001b[K     |██████▍                         | 327kB 2.7MB/s eta 0:00:01\r\u001b[K     |██████▋                         | 337kB 2.7MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 348kB 2.7MB/s eta 0:00:01\r\u001b[K     |███████                         | 358kB 2.7MB/s eta 0:00:01\r\u001b[K     |███████▏                        | 368kB 2.7MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 378kB 2.7MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 389kB 2.7MB/s eta 0:00:01\r\u001b[K     |███████▊                        | 399kB 2.7MB/s eta 0:00:01\r\u001b[K     |████████                        | 409kB 2.7MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 419kB 2.7MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 430kB 2.7MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 440kB 2.7MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 450kB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████                       | 460kB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 471kB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████▍                      | 481kB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 491kB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 501kB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████                      | 512kB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 522kB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 532kB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 542kB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████▊                     | 552kB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████                     | 563kB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 573kB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 583kB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 593kB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 604kB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████                    | 614kB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 624kB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 634kB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████▌                   | 645kB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████▊                   | 655kB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 665kB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████████▏                  | 675kB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 686kB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 696kB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 706kB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 716kB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████████▏                 | 727kB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 737kB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 747kB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 757kB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 768kB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 778kB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 788kB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████████▌                | 798kB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 808kB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████████                | 819kB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████████▏               | 829kB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 839kB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 849kB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 860kB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 870kB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████████████▏              | 880kB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 890kB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 901kB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 911kB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 921kB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 931kB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 942kB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 952kB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████████████▊             | 962kB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 972kB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 983kB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 993kB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████████████▌            | 1.0MB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 1.0MB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 1.0MB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 1.0MB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 1.0MB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 1.1MB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████████████▊           | 1.1MB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 1.1MB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 1.1MB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 1.1MB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████▌          | 1.1MB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 1.1MB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 1.1MB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 1.1MB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 1.1MB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████▌         | 1.2MB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 1.2MB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 1.2MB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 1.2MB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 1.2MB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 1.2MB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 1.2MB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 1.2MB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 1.2MB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 1.2MB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████▌       | 1.3MB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 1.3MB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 1.3MB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 1.3MB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▎      | 1.3MB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 1.3MB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▊      | 1.3MB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 1.3MB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 1.3MB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▎     | 1.4MB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 1.4MB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 1.4MB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 1.4MB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 1.4MB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 1.4MB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 1.4MB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▊    | 1.4MB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 1.4MB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 1.4MB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▎   | 1.5MB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 1.5MB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 1.5MB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 1.5MB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 1.5MB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▎  | 1.5MB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 1.5MB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 1.5MB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 1.5MB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 1.5MB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 1.6MB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 1.6MB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▋ | 1.6MB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 1.6MB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 1.6MB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 1.6MB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 1.6MB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 1.6MB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 1.6MB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.6MB 2.7MB/s \n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from foolbox==3.0.0b1) (1.18.5)\n","Collecting eagerpy==0.25.2\n","  Downloading https://files.pythonhosted.org/packages/0f/fa/8d52cefda0d21b7262a18d745f5d6e07e035093118947b070eb4ca449557/eagerpy-0.25.2-py3-none-any.whl\n","Requirement already satisfied: typing-extensions>=3.7.4.1 in /usr/local/lib/python3.6/dist-packages (from foolbox==3.0.0b1) (3.7.4.2)\n","Collecting GitPython>=3.0.7\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f9/1e/a45320cab182bf1c8656107b3d4c042e659742822fc6bff150d769a984dd/GitPython-3.1.7-py3-none-any.whl (158kB)\n","\u001b[K     |████████████████████████████████| 163kB 17.3MB/s \n","\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from foolbox==3.0.0b1) (1.4.1)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from foolbox==3.0.0b1) (49.2.0)\n","Collecting gitdb<5,>=4.0.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/48/11/d1800bca0a3bae820b84b7d813ad1eff15a48a64caea9c823fc8c1b119e8/gitdb-4.0.5-py3-none-any.whl (63kB)\n","\u001b[K     |████████████████████████████████| 71kB 7.2MB/s \n","\u001b[?25hCollecting smmap<4,>=3.0.1\n","  Downloading https://files.pythonhosted.org/packages/b0/9a/4d409a6234eb940e6a78dfdfc66156e7522262f5f2fecca07dc55915952d/smmap-3.0.4-py2.py3-none-any.whl\n","Installing collected packages: eagerpy, smmap, gitdb, GitPython, foolbox\n","Successfully installed GitPython-3.1.7 eagerpy-0.25.2 foolbox-3.0.0b1 gitdb-4.0.5 smmap-3.0.4\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"n0vvAzdAPUMx","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1597044706389,"user_tz":-270,"elapsed":10894,"user":{"displayName":"Bardia Esmaeili","photoUrl":"","userId":"04990908225233460923"}}},"source":["import foolbox as fb"],"execution_count":24,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"tXTcgJCvfydg","colab_type":"text"},"source":["Base and Student Model with Temperature 1 for Softmax"]},{"cell_type":"code","metadata":{"id":"VIXV-IpdPyqX","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1597062493311,"user_tz":-270,"elapsed":1319,"user":{"displayName":"Bardia Esmaeili","photoUrl":"","userId":"04990908225233460923"}}},"source":["base_with_softmax = Sequential([base_model, Activation('softmax')])\n","sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n","base_with_softmax.compile(loss='categorical_crossentropy',\n","              optimizer=sgd,\n","              metrics=['accuracy'])\n","# print(base_model.summary())\n","# print(base_with_softmax.summary())\n","\n","student_with_softmax = Sequential([student, Activation('softmax')])\n","sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n","student_with_softmax.compile(loss='categorical_crossentropy',\n","              optimizer=sgd,\n","              metrics=['accuracy'])\n","# print(student.summary())\n","# print(student_with_softmax.summary())"],"execution_count":83,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"BZR4e7NNgFKJ","colab_type":"text"},"source":["Test robustness of Base Model"]},{"cell_type":"code","metadata":{"id":"5CvO52ucPb0w","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":54},"executionInfo":{"status":"ok","timestamp":1597062511640,"user_tz":-270,"elapsed":1936,"user":{"displayName":"Bardia Esmaeili","photoUrl":"","userId":"04990908225233460923"}},"outputId":"71f9cb71-6722-4d93-bebb-9e9eb4573680"},"source":["mnist_instance = MNIST()\n","raw, clipped, is_adv = None, None, None\n","fb_data = tf.constant(mnist_instance.test_data[:1000], dtype = tf.float32)\n","fb_label = tf.constant(np.argmax(mnist_instance.test_labels[:1000], axis = -1))\n","# fb_label = tf.constant([1, 1] - to_categorical(labels[random_idx:random_idx + 1]))\n","preprocessing = dict()\n","bounds = (0, 1)\n","fmodel = fb.TensorFlowModel(base_with_softmax, bounds=bounds, preprocessing=preprocessing)\n","raw, clipped, is_adv = fb.attacks.FGSM()(fmodel, fb_data, fb_label, epsilons =  [0.4])\n","print(np.mean(is_adv[0]))"],"execution_count":84,"outputs":[{"output_type":"stream","text":["(60000, 10) (10000, 10)\n","0.55\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"QCGGth1qgJUS","colab_type":"text"},"source":["Test robustness of student model"]},{"cell_type":"code","metadata":{"id":"bmAly59sR4Bg","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":54},"executionInfo":{"status":"ok","timestamp":1597062638617,"user_tz":-270,"elapsed":1874,"user":{"displayName":"Bardia Esmaeili","photoUrl":"","userId":"04990908225233460923"}},"outputId":"f2054678-5877-468c-d344-0ca23cb2962b"},"source":["mnist_instance = MNIST()\n","raw, clipped, is_adv = None, None, None\n","fb_data = tf.constant(mnist_instance.test_data[:1000], dtype = tf.float32)\n","fb_label = tf.constant(np.argmax(mnist_instance.test_labels[:1000], axis=-1))\n","# fb_label = tf.constant([1, 1] - to_categorical(labels[random_idx:random_idx + 1]))\n","preprocessing = dict()\n","bounds = (0, 1)\n","fmodel = fb.TensorFlowModel(student_with_softmax, bounds=bounds, preprocessing=preprocessing)\n","raw, clipped, is_adv = fb.attacks.FGSM()(fmodel, fb_data, fb_label, epsilons =  [0.4])\n","print(np.mean(is_adv[0]))"],"execution_count":87,"outputs":[{"output_type":"stream","text":["(60000, 10) (10000, 10)\n","0.01\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"JqK81w3VewxE","colab_type":"text"},"source":["References:\n","\n","\n","*   https://github.com/carlini/nn_robust_attacks\n","\n","\n"]}]}